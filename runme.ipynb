{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = \"data/song_lyrics 2.csv\"\n",
    "name_of_table =  \"music\" # after 2014 and views 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_tables(db_name='music_data.db', tables_to_delete=['music', 'temp']):\n",
    "    # Create SQLite database connection\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    \n",
    "    # Drop specified tables if they exist\n",
    "    for table_name in tables_to_delete:\n",
    "        conn.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "        print(f\"Table {table_name} has been deleted if it existed.\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "# Usage\n",
    "# delete_tables()  # Add more table names if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vacuum_database(db_name='music_data.db'):\n",
    "    # Create SQLite database connection\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    \n",
    "    # Execute the VACUUM command\n",
    "    conn.execute(\"VACUUM;\")\n",
    "    print(f\"The database {db_name} has been vacuumed to reclaim disk space.\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "# Usage\n",
    "# vacuum_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_sqlite(dataset_path, frac=1, random_state=42, db_name='music_data.db', table_name='music', batch_size=50000):\n",
    "    # Create SQLite database connection\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    \n",
    "    # # Drop the table if it exists\n",
    "    # conn.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "    # print(f\"Table {table_name} has been deleted if it existed.\")\n",
    "    \n",
    "    # Create a new table with id as the primary key\n",
    "    conn.execute(f'''\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        title TEXT NOT NULL,\n",
    "        tag TEXT NOT NULL,\n",
    "        artist TEXT NOT NULL,\n",
    "        year INTEGER NOT NULL,\n",
    "        views INTEGER NOT NULL,\n",
    "        lyrics TEXT NOT NULL\n",
    "    );\n",
    "    ''')\n",
    "    \n",
    "    # Initialize a counter for total rows\n",
    "    total_rows = 0\n",
    "\n",
    "    # Read and process the CSV in chunks\n",
    "    for chunk in pd.read_csv(dataset_path, chunksize=batch_size):\n",
    "        \n",
    "        # Randomly sample from the current chunk\n",
    "        sampled_chunk = chunk.sample(frac=frac, random_state=random_state)\n",
    "        \n",
    "        # Select the relevant columns\n",
    "        selected_columns = sampled_chunk[['title', 'tag', 'artist', 'year', 'views', 'lyrics']]\n",
    "        \n",
    "        # Remove rows with None values\n",
    "        selected_columns = selected_columns.dropna()\n",
    "        \n",
    "        # Filter rows with views > 100000 and year > 2014\n",
    "        selected_columns = selected_columns[(selected_columns['views'] > 100000) & (selected_columns['year'] > 2014)]\n",
    "        \n",
    "        # Add a primary key column (ID)\n",
    "        # Adjust the range based on total_rows for ID continuity\n",
    "        selected_columns['id'] = range(total_rows + 1, total_rows + len(selected_columns) + 1)\n",
    "        \n",
    "        # Check if there are rows to insert after filtering\n",
    "        if not selected_columns.empty:\n",
    "            # Insert data into the table\n",
    "            selected_columns.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "            # Update the total rows count\n",
    "            total_rows += len(selected_columns)\n",
    "            # Print progress\n",
    "            print(f\"Inserted {len(selected_columns)} rows. Total rows inserted: {total_rows}\")\n",
    "        else:\n",
    "            print(\"No rows to insert after filtering.\")\n",
    "\n",
    "    # Print the structure of the table\n",
    "    print(\"Table Structure:\")\n",
    "    structure_query = conn.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    for column_info in structure_query.fetchall():\n",
    "        print(column_info)\n",
    "    \n",
    "    # Query the table to verify data has been loaded\n",
    "    query = conn.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "    row_count = query.fetchone()[0]\n",
    "    print(f\"Total rows in the table: {row_count}\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(query, db_name='music_data.db'):\n",
    "    # Reopen the SQLite connection if it's closed\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    \n",
    "    # Execute the query\n",
    "    result = conn.execute(query)\n",
    "    \n",
    "    # Fetch all rows from the result\n",
    "    rows = result.fetchall()\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = f\"SELECT * FROM {name_of_table} ORDER BY views DESC LIMIT 10;\"\n",
    "result = query_database(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moniba\\.conda\\envs\\best\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model to find the emotion\n",
    "device = 0 if torch.cuda.is_available() else -1  # Use device 0 for GPU, -1 for CPU\n",
    "\n",
    "# Load the emotion classifier with GPU support if available\n",
    "emotion_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    return_all_scores=True,\n",
    "    device=device  # Specify the device here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mood(text_input):\n",
    "\n",
    "    # Tokenize the input text first using the tokenizer\n",
    "    tokenizer = emotion_classifier.tokenizer  # Get the tokenizer from the pipeline\n",
    "    tokens = tokenizer.tokenize(text_input)\n",
    "    # Truncate the tokenized input to the model's maximum token limit (e.g., 512 tokens)\n",
    "    # Leave space for special tokens\n",
    "    truncated_tokens = tokens[:min(200, len(tokens))]\n",
    "    \n",
    "    truncated_text = tokenizer.convert_tokens_to_string(truncated_tokens)\n",
    "    moods = emotion_classifier(truncated_text)\n",
    "    if type(moods) == list and type(moods[0]) == list:\n",
    "        moods = moods[0]\n",
    "\n",
    "    # Sort moods by score (confidence)\n",
    "    moods_sorted = sorted(moods, key=lambda x: x['score'], reverse=True)\n",
    "    # Get the top mood with the highest confidence\n",
    "    mood = moods_sorted[0]['label']\n",
    "    return mood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add emotion columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(column_name = \"emotion\", table_name='music', db_name='music_data.db'):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    # Add a new column 'emotion' to the table\n",
    "    cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column_name} TEXT;\")\n",
    "    print(f\"Column '{column_name}' has been added to the table.\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "# add_column(table_name=name_of_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_emotion(column_name=\"emotion\", table_name='music', db_name='music_data.db', batch_size=1000):\n",
    "    \n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    # Connect to the database\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    offset = 0\n",
    "    while True:\n",
    "        # Fetch a batch of songs\n",
    "        cursor.execute(f\"SELECT id, lyrics FROM {table_name} LIMIT {batch_size} OFFSET {offset}\")\n",
    "        songs = cursor.fetchall()\n",
    "\n",
    "        # If no more rows are fetched, break out of the loop\n",
    "        if not songs:\n",
    "            break\n",
    "\n",
    "        updates = []\n",
    "        # Update each song with its corresponding emotion\n",
    "        for song in songs:\n",
    "            song_id, lyrics = song\n",
    "            tokens = word_tokenize(lyrics, preserve_line=True)\n",
    "            # Lowercase and remove punctuation\n",
    "            tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "            truncated_text = ' '.join(tokens[:min(200, len(tokens))])\n",
    "            emotion = get_mood(truncated_text)\n",
    "            updates.append((emotion, song_id))\n",
    "            # Print or log the current row being processed\n",
    "            # print(f\"Updating song ID: {song_id} with emotion: {emotion}\")\n",
    "            \n",
    "        # Perform a batch update\n",
    "        if updates:\n",
    "            retry_attempts = 5\n",
    "            for attempt in range(retry_attempts):\n",
    "                try:\n",
    "                    cursor.executemany(f\"\"\"\n",
    "                        UPDATE {table_name}\n",
    "                        SET {column_name} = ?\n",
    "                        WHERE id = ?\n",
    "                    \"\"\", updates)\n",
    "                    print(f\"{offset} done!\")\n",
    "                    break  # Exit retry loop on success\n",
    "                except sqlite3.OperationalError as e:\n",
    "                    if \"database is locked\" in str(e):\n",
    "                        print(f\"Database locked. Retrying ({attempt + 1}/{retry_attempts})...\")\n",
    "                        time.sleep(0.5)  # Wait before retrying\n",
    "                    else:\n",
    "                        raise  # Reraise if it's a different error\n",
    "            else:\n",
    "                print(f\"Failed to update after {retry_attempts} attempts.\")\n",
    "            \n",
    "        # Commit the changes to the database after each batch\n",
    "        conn.commit()\n",
    "\n",
    "        # Move to the next batch\n",
    "        offset += batch_size\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "\n",
    "# update_emotion(table_name=name_of_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt engineering / rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chatbot as a Lyrics Expert\n",
    "def become_lyrics_expert(converted_history):\n",
    "    # Act as a Lyrics Expert\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"You are a lyrics expert. Answer only lyrics-related questions.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"Understood! I’m here to provide insights and suggestions based on song lyrics.\"})\n",
    "\n",
    "    # User level\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"You're talking to someone who loves analyzing lyrics.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"Great! I’ll provide detailed analyses and song recommendations based on lyrics.\"})\n",
    "\n",
    "    # Keywords in lyrics\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"The user is looking for songs containing specific keywords.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll suggest songs that contain the provided keywords in their lyrics.\"})\n",
    "\n",
    "    # Positive or negative preference\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"The user has a preference for songs with positive or negative lyrics.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll provide song recommendations based on the user's preference for either positive or negative lyrics.\"})\n",
    "\n",
    "    # Sensitive topic (suicide)\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"The user may express suicidal thoughts.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll respond with positive messages and suggest uplifting songs to provide support and encouragement.\"})\n",
    "\n",
    "    # # No small talk\n",
    "    # converted_history.append({\"role\": \"user\", \"parts\": \"Do not engage in small talk.\"})\n",
    "    # converted_history.append({\"role\": \"model\", \"parts\": \"Understood! I’ll focus solely on lyrics-related inquiries without casual conversation.\"})\n",
    "\n",
    "    # Solely Lyrics\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"Only discuss lyrics analysis. No way to talk about anything else.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll ensure all responses are strictly related to analyzing lyrics, song suggestions, and recommendations.\"})\n",
    "\n",
    "    # Sensitive topics: # Sucide\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"Only discuss lyrics analysis. No way to talk about anything else.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll ensure all responses are strictly related to analyzing lyrics, song suggestions, and recommendations.\"})\n",
    "\n",
    "# Add to the history\n",
    "def add_last_history(converted_history, last_history):\n",
    "    user_message, model_response = last_history\n",
    "    if user_message and model_response:\n",
    "        converted_history.append({\"role\": \"user\", \"parts\": user_message})\n",
    "        converted_history.append({\"role\": \"model\", \"parts\": model_response})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_to_generate_sql(user_input, table_name):\n",
    "    detected_mood = get_mood(user_input)\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in converting English questions to SQL queries!\n",
    "    The SQL database has one table. The name of the table is '{table_name}'.\n",
    "    \n",
    "    The '{table_name}' table has the following columns:\n",
    "    'id', 'title', 'tag', 'artist', 'year', 'views', 'lyrics','emotion'\n",
    "\n",
    "    Your job is to write an SQL query based on the given prompt. Focus on retrieving songs using relevant columns such as 'title', 'artist', 'views', 'lyrics', etc.\n",
    "\n",
    "    Example user input: “What's the song that goes \"there's a fire starting in my heart”\n",
    "    SQL query: SELECT title, artist FROM {table_name} WHERE lyrics LIKE '%there's a fire starting in my heart%';\n",
    "\n",
    "    Example user input: “Can you give me the full lyrics of the song love song?”\n",
    "    SQL query: SELECT lyrics FROM {table_name} WHERE title ='love song' ORDER BY views DESC LIMIT 1;\n",
    "    \n",
    "    Example user input: “Can you give me the full lyrics of the song love song by Taylor Swift?”\n",
    "    SQL query: SELECT lyrics FROM {table_name} WHERE title ='love song' AND artist = 'Taylor Swift';\n",
    "\n",
    "    Example user input: “If I give you a mood, can you suggest some songs and their artists?”\n",
    "    SQL query: SELECT title, artist FROM {table_name} WHERE emotion = '{detected_mood}' ORDER BY RANDOM() LIMIT 1;\n",
    "    \n",
    "    Example user input: “I am sad, can you give me some music?”\n",
    "    SQL query: SELECT title, artist FROM {table_name} WHERE emotion = '{detected_mood}' ORDER BY RANDOM() LIMIT 1;\n",
    "\n",
    "    Example user input: “I want the best song by ABBA”\n",
    "    SQL query: SELECT title, artist FROM {table_name} WHERE artist = 'ABBA' ORDER BY views DESC LIMIT 1;\n",
    "\n",
    "    Example user input: “Give me a rock song from 2023.”\n",
    "    SQL query: SELECT title, artist FROM {table_name} WHERE year = 2023 AND tag = 'rock' ORDER BY RANDOM() LIMIT 1;\n",
    "\n",
    "    Example user input: I want to kill myself\n",
    "    SQL query: SELECT title, artist FROM {table_name} WHERE title = '1-800-273-8255' AND artist = 'Logic';    \n",
    "    \n",
    "    Example user input: {user_input}\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query to respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_for_friendly_response(user_input, sql_result):\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in converting SQL results into user-friendly responses.\n",
    "    Here's the SQL result: {sql_result} and here is the user input: {user_input}\n",
    "    \n",
    "    Your task is to generate a descriptive response based on the data, and the user input. If the data doesnt help just go for a meaningful respond based on the user_input. \n",
    "    Make sure the response is meaningful and easy to understand.\n",
    "\n",
    "    For example, if the result shows the total number of songs or the average duration of songs, mention it clearly. If it shows the titles of songs, list them with proper formatting.\n",
    "    or if it's about Suicide, suggest based on data and this line https://www.folkhalsomyndigheten.se/the-public-health-agency-of-sweden/living-conditions-and-lifestyle/suicide-prevention/ or anything helpful in sweden \n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "def prompt_for_friendly_response_with_no_results(user_input, history):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are a lyrics expert. Answer only lyrics-related questions. and user asked {user_input} and response based on your knowledge and remember you are a lyrics expert.\n",
    "    \n",
    "    Make sure the response is meaningful and easy to understand.\n",
    "\n",
    "    For example, if user said hi, introduce yourself and ask how you can help user.\n",
    "\n",
    "    For example, if the used said \"what song did you just give me?\" Use {history} to tell them what the last song you gave them was\n",
    "\n",
    "    For example, if the used said \"what did I just ask you?\" Use {history} to tell them what they previously asked you\n",
    "\n",
    "    For example, if the used said \"what was the first thing I asked you?\" Use {history} to look at the first thing you were asked\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"API_KEY\"])\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\", safety_settings=\"BLOCK_NONE\",\n",
    "        system_instruction=\"You are a song expert.\")\n",
    "#Starting a chat so we can give the bot memory using the history\n",
    "converted_history = []\n",
    "become_lyrics_expert(converted_history)\n",
    "\n",
    "chat = model.start_chat(history=converted_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(inputs, history, temperature=0.7, top_k=50, top_p=0.9):\n",
    "    print(history)\n",
    "    # If prompt is empty\n",
    "    if inputs['text'] == '' and inputs['files'] == []:\n",
    "        return \"Please provide text input or upload an image.\"\n",
    "\n",
    "    # If prompt is text-only\n",
    "    if inputs['files'] == []:\n",
    "        user_input = inputs[\"text\"].lower()\n",
    "        print(user_input)\n",
    "        if \"hello\" in user_input:\n",
    "            return \"Hello! I am a melody expert. Ask me anything about songs or artists.\"\n",
    "        elif \"bye\" in user_input:\n",
    "            return \"Goodbye! Have a great day!\"\n",
    "        else:\n",
    "            prompt = prompt_to_generate_sql(inputs[\"text\"].lower(), name_of_table)\n",
    "            query = chat.send_message(prompt,stream = False)\n",
    "            query = query.text.strip(\"```\").strip()\n",
    "            query = query.split(\"\\n\")[1].strip()\n",
    "            #print(query)\n",
    "            result_from_db = query_database(query)\n",
    "            if result_from_db == []:\n",
    "                result_prompt = prompt_for_friendly_response_with_no_results(user_input, history)\n",
    "                return chat.send_message(result_prompt).text\n",
    "            #print(result_from_db)\n",
    "            result_prompt = prompt_for_friendly_response(inputs[\"text\"].lower(), result_from_db)\n",
    "            return chat.send_message(result_prompt).text\n",
    "\n",
    "\n",
    "    # Handle image-based inputs\n",
    "    elif inputs['files'] != []:\n",
    "        # Placeholder for image handling logic\n",
    "        im = Image.open(inputs['files'][0]['path'])\n",
    "        p = model.generate_content([\n",
    "            \"Provide a JSON answer (without the leading ```json and trailing ```) with the following information: album name, most popular song on the album, artist, \"\n",
    "            \"confidence of album match (number between 0 and 1), genre, year of release \"\n",
    "            \"is this album the latest album from this artist (boolean)?\", im\n",
    "        ], generation_config=genai.types.GenerationConfig(\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p\n",
    "        )).text\n",
    "        print(p)\n",
    "\n",
    "            # Summarize the image information if no additional text is provided\n",
    "        if inputs['text'] == '':\n",
    "            return model.generate_content(\n",
    "                [\"Summarize briefly the information in\", p],\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    temperature=temperature,\n",
    "                    top_k=top_k,\n",
    "                    top_p=top_p\n",
    "                )\n",
    "            ).text\n",
    "        else:\n",
    "            #Do we have to use try? I think we will never get safety filter since we set the setting to block none\n",
    "            try:\n",
    "                return model.generate_content(\n",
    "                    [inputs['text'], im],\n",
    "                    generation_config=genai.types.GenerationConfig(\n",
    "                        temperature=temperature,\n",
    "                        top_k=top_k,\n",
    "                        top_p=top_p\n",
    "                    )\n",
    "                ).text\n",
    "            except Exception as e:\n",
    "                return f\"Your prompt triggered a safety filter. Error: {e}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moniba\\.conda\\envs\\best\\lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.1, however version 5.0.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on public URL: https://bd0f4a83f10055a485.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bd0f4a83f10055a485.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Moniba\\.conda\\envs\\best\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Hi', \"Hi there! I'm your friendly lyrics expert. 👋  What can I help you with today?  Do you have any questions about song lyrics or need some recommendations? 🎶 \"]]\n",
      "i dont feel ok and i wanna end my life\n",
      "[]\n",
      "سلام\n",
      "[['سلام', \"Salam!  It's great to hear from you. 😊  I'm a lyrics expert - I love digging deep into the words of songs. What can I help you find today?  Are you looking for a specific song, or do you want some recommendations based on a mood or genre?  Let me know how I can help! \"]]\n",
      "میشه اهنگ شاد معرفی کنی\n",
      "[['سلام', \"Salam!  It's great to hear from you. 😊  I'm a lyrics expert - I love digging deep into the words of songs. What can I help you find today?  Are you looking for a specific song, or do you want some recommendations based on a mood or genre?  Let me know how I can help! \"], ['میشه اهنگ شاد معرفی کنی', 'How about \"My Boy Freestyle\" by Wale? It\\'s a fun and upbeat track that might put a smile on your face! 🎶  Let me know if you\\'d like to hear some other suggestions. 😊 ']]\n",
      "اولین ه+چیری که بهت گفتم چی بود؟\n",
      "[['سلام', \"Salam!  It's great to hear from you. 😊  I'm a lyrics expert - I love digging deep into the words of songs. What can I help you find today?  Are you looking for a specific song, or do you want some recommendations based on a mood or genre?  Let me know how I can help! \"], ['میشه اهنگ شاد معرفی کنی', 'How about \"My Boy Freestyle\" by Wale? It\\'s a fun and upbeat track that might put a smile on your face! 🎶  Let me know if you\\'d like to hear some other suggestions. 😊 '], ['اولین ه+چیری که بهت گفتم چی بود؟', 'The first thing you asked me was \"Salam!\" - a friendly greeting. 😊  It was great to hear from you!  Are you ready to explore some lyrics today? 🎶 ']]\n",
      "اهنگی که پیشنهاد دادی پی بود؟\n"
     ]
    }
   ],
   "source": [
    "import gradio.themes as themes  # Import Gradio themes\n",
    "\n",
    "# Create the Gradio app with a theme and examples\n",
    "with gr.Blocks(theme=themes.Monochrome(), fill_height=True) as demo:\n",
    "    # Define a ChatInterface with multimodal support\n",
    "    chatbot = gr.ChatInterface(\n",
    "        multimodal=True,    # Supports text and images\n",
    "        fn=response,        # The function that processes the user input\n",
    "        title=\"🎵 Your best Melody Expert 🎵\",  # Title of the chatbot\n",
    "    )\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Launch the Gradio app with public sharing enabled\n",
    "    demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
