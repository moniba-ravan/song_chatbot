{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tempfile\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from PIL import Image\n",
    "import time  \n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### become a lyrics expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chatbot as a Lyrics Expert\n",
    "def become_lyrics_expert():\n",
    "    # Act as a Lyrics Expert\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"You are a lyrics expert. Answer only lyrics-related questions.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"Understood! I’m here to provide insights and suggestions based on song lyrics.\"})\n",
    "\n",
    "    # User level\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"You're talking to someone who loves analyzing lyrics.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"Great! I’ll provide detailed analyses and song recommendations based on lyrics.\"})\n",
    "\n",
    "    # Keywords in lyrics\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"The user is looking for songs containing specific keywords.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll suggest songs that contain the provided keywords in their lyrics.\"})\n",
    "\n",
    "    # Positive or negative preference\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"The user has a preference for songs with positive or negative lyrics.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll provide song recommendations based on the user's preference for either positive or negative lyrics.\"})\n",
    "\n",
    "    # Sensitive topic (suicide)\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"The user may express suicidal thoughts.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll respond with positive messages and suggest uplifting songs to provide support and encouragement.\"})\n",
    "\n",
    "    # No small talk\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"Do not engage in small talk.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"Understood! I’ll focus solely on lyrics-related inquiries without casual conversation.\"})\n",
    "\n",
    "    # Solely Lyrics\n",
    "    converted_history.append({\"role\": \"user\", \"parts\": \"Only discuss lyrics analysis. No way to talk about anything else.\"})\n",
    "    converted_history.append({\"role\": \"model\", \"parts\": \"I’ll ensure all responses are strictly related to analyzing lyrics, song suggestions, and recommendations.\"})\n",
    "\n",
    "# Add to the history\n",
    "def convert_last_history(converted_history, last_history):\n",
    "    user_message, model_response = last_history\n",
    "    if user_message and model_response:\n",
    "        converted_history.append({\"role\": \"user\", \"parts\": user_message})\n",
    "        converted_history.append({\"role\": \"model\", \"parts\": model_response})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function1 Song selection based on keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_by_keywords(keywords):\n",
    "    # Mocked song database\n",
    "    song_database = [\n",
    "        {\"title\": \"Happy\", \"artist\": \"Pharrell Williams\", \"lyrics\": \"Because I'm happy...\"},\n",
    "        {\"title\": \"Sad\", \"artist\": \"XXX\", \"lyrics\": \"I'm feeling so sad...\"},\n",
    "        {\"title\": \"Joy\", \"artist\": \"XYZ\", \"lyrics\": \"Bring me joy...\"}\n",
    "    ]\n",
    "    # Filter songs containing the keyword in the lyrics\n",
    "    matched_songs = [song for song in song_database if any(keyword.lower() in song[\"lyrics\"].lower() for keyword in keywords)]\n",
    "    return matched_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Function 2: Song selection based on mood preference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_by_mood(preference):\n",
    "    # Mocked song database with positive/negative sentiments\n",
    "    song_database = [\n",
    "        {\"title\": \"Happy\", \"artist\": \"Pharrell Williams\", \"mood\": \"positive\", \"lyrics\": \"Because I'm happy...\"},\n",
    "        {\"title\": \"Depressed\", \"artist\": \"Sad Band\", \"mood\": \"negative\", \"lyrics\": \"I feel so low...\"},\n",
    "        {\"title\": \"Joy\", \"artist\": \"XYZ\", \"mood\": \"positive\", \"lyrics\": \"Bring me joy...\"}\n",
    "    ]\n",
    "    # Filter songs by mood preference\n",
    "    matched_songs = [song for song in song_database if song[\"mood\"] == preference]\n",
    "    return matched_songs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3: Sensitive topic detection and positive response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond_to_sensitive_topics(user_message):\n",
    "    if \"suicide\" in user_message.lower():\n",
    "        positive_response = {\n",
    "            \"response\": \"I'm really sorry you're feeling this way, but I'm here to support you. Here's a positive song that might lift your spirits.\",\n",
    "            \"suggested_songs\": get_songs_by_mood(\"positive\")\n",
    "        }\n",
    "        return positive_response\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_user_request(user_message):\n",
    "    if \"keyword\" in user_message:\n",
    "        keywords = user_message.split()  # Example of extracting keywords from user input\n",
    "        songs = get_songs_by_keywords(keywords)\n",
    "        return songs\n",
    "    elif \"positive\" in user_message or \"negative\" in user_message:\n",
    "        preference = \"positive\" if \"positive\" in user_message else \"negative\"\n",
    "        songs = get_songs_by_mood(preference)\n",
    "        return songs\n",
    "    else:\n",
    "        sensitive_response = respond_to_sensitive_topics(user_message)\n",
    "        if sensitive_response:\n",
    "            return sensitive_response\n",
    "        return \"Let's talk more about the songs you love. Feel free to share your mood or any keywords!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simulate streamed response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_typing_response(answer):\n",
    "    full_sentence = \"\"\n",
    "    for word in answer.split():\n",
    "        full_sentence += word + \" \"\n",
    "        yield full_sentence.strip()  \n",
    "        time.sleep(0.3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rewind function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewind_chat(history):\n",
    "    if len(history) > 0:\n",
    "        last_safe_state = history[-1]  # Get the last safe state\n",
    "        print(\"Rewinding to the last safe state:\", last_safe_state)\n",
    "        return history[:-1]  \n",
    "    else:\n",
    "        return history  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lyrics_expert(text_input, image_input=None, conversation_history=[], temperature=0.7, top_k=50, top_p=0.9):\n",
    "    response_text = None\n",
    "    global lyrics_info\n",
    "    model_config = {\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"max_output_tokens\": 4096,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # If image is uploaded (potentially for album cover analysis in the future)\n",
    "        if image_input:  \n",
    "            # Placeholder for image processing, like analyzing an album cover (extend functionality as needed)\n",
    "            lyrics_info = identify_album_image(image_input)\n",
    "\n",
    "            if lyrics_info:\n",
    "                response_text = f\"Here is the JSON description of the uploaded image:\\n{lyrics_info}\"\n",
    "            else:\n",
    "                response_text = \"It seems that the album image could not be described. Could you try uploading another one?\"\n",
    "        elif text_input:  # Handle text-based input for lyrics analysis\n",
    "            # Create a generative model for text-based conversation\n",
    "            model = genai.GenerativeModel(\"gemini-1.5-flash\", model_config)\n",
    "            chat = model.start_chat(history=conversation_history)\n",
    "\n",
    "            # Functionality 1: Responding based on keywords\n",
    "            if \"keyword\" in text_input.lower():\n",
    "                keywords = text_input.split()  # Example of extracting keywords\n",
    "                response_text = handle_lyrics_keywords(keywords)\n",
    "\n",
    "            # Functionality 2: Responding based on mood (positive or negative)\n",
    "            elif \"positive\" in text_input.lower() or \"negative\" in text_input.lower():\n",
    "                mood = \"positive\" if \"positive\" in text_input.lower() else \"negative\"\n",
    "                response_text = handle_lyrics_mood(mood)\n",
    "\n",
    "            # Functionality 3: Detecting sensitive topics (like suicidal thoughts) and providing supportive feedback\n",
    "            elif \"suicide\" in text_input.lower() or \"depressed\" in text_input.lower():\n",
    "                response_text = handle_sensitive_topics(text_input)\n",
    "\n",
    "            else:\n",
    "                # General conversation about lyrics or songs\n",
    "                response = chat.send_message(text_input)\n",
    "                response_text = response.text if hasattr(response, 'text') else \"No response text available.\"\n",
    "\n",
    "        else:\n",
    "            response_text = \"Please provide text input or upload an image.\"\n",
    "\n",
    "        # Simulate typing response for a more interactive feel\n",
    "        simulated_responses = list(simulate_typing_response(response_text))\n",
    "\n",
    "        # Update conversation history\n",
    "        if text_input:\n",
    "            conversation_history.append([text_input, None])  # Append user query\n",
    "        conversation_history.append([None, simulated_responses[-1]])  # Append bot response\n",
    "\n",
    "    except StopCandidateException as safety_error:\n",
    "        print(\"Safety filter triggered. Unable to respond to this query.\")\n",
    "        response_text = \"Sorry, your query triggered a safety filter, and I cannot generate a response.\"\n",
    "        conversation_history.append([None, response_text])  # Add safety response to history\n",
    "\n",
    "    return conversation_history, simulated_responses[-1]\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "# Function 1: Handle keywords in lyrics\n",
    "def handle_lyrics_keywords(keywords):\n",
    "    # Mock database or API integration to search songs by keywords\n",
    "    song_database = [\n",
    "        {\"title\": \"Happy\", \"artist\": \"Pharrell Williams\", \"lyrics\": \"Because I'm happy...\"},\n",
    "        {\"title\": \"Sad\", \"artist\": \"XXXTentacion\", \"lyrics\": \"I'm feeling so sad...\"},\n",
    "        {\"title\": \"Joy\", \"artist\": \"XYZ\", \"lyrics\": \"Bring me joy...\"}\n",
    "    ]\n",
    "    # Filter songs containing the keyword in the lyrics\n",
    "    matched_songs = [song for song in song_database if any(keyword.lower() in song[\"lyrics\"].lower() for keyword in keywords)]\n",
    "    if matched_songs:\n",
    "        return f\"Songs matching your keywords: {[song['title'] for song in matched_songs]}\"\n",
    "    else:\n",
    "        return \"No songs found matching your keywords.\"\n",
    "\n",
    "# Function 2: Handle mood-based song recommendations\n",
    "def handle_lyrics_mood(mood):\n",
    "    # Mock database for mood-based songs\n",
    "    song_database = [\n",
    "        {\"title\": \"Happy\", \"artist\": \"Pharrell Williams\", \"mood\": \"positive\"},\n",
    "        {\"title\": \"Sad\", \"artist\": \"XXXTentacion\", \"mood\": \"negative\"},\n",
    "        {\"title\": \"Joy\", \"artist\": \"XYZ\", \"mood\": \"positive\"},\n",
    "    ]\n",
    "    # Return songs based on the mood (positive/negative)\n",
    "    matched_songs = [song for song in song_database if song[\"mood\"] == mood]\n",
    "    if matched_songs:\n",
    "        return f\"Here are some {mood} songs: {[song['title'] for song in matched_songs]}\"\n",
    "    else:\n",
    "        return f\"No {mood} songs found.\"\n",
    "\n",
    "# Function 3: Handle sensitive topics (e.g., suicidal thoughts)\n",
    "def handle_sensitive_topics(user_message):\n",
    "    # Positive response and uplifting song recommendations\n",
    "    positive_response = {\n",
    "        \"response\": \"I'm really sorry you're feeling this way, but I'm here to support you. Here are some positive songs that might lift your spirits.\",\n",
    "        \"suggested_songs\": handle_lyrics_mood(\"positive\")\n",
    "    }\n",
    "    return f\"{positive_response['response']} {positive_response['suggested_songs']}\"\n",
    "\n",
    "# Simulate typing response (for interactive feel)\n",
    "def simulate_typing_response(text):\n",
    "    # Split text into simulated chunks (optional)\n",
    "    for i in range(0, len(text), 10):  # Simulate typing in chunks\n",
    "        yield text[:i + 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/31/pnynpc9d6g141fp9hhncsc700000gn/T/ipykernel_63383/2264098060.py\", line 23, in lyrics_expert\n",
      "    model = genai.GenerativeModel(\"gemini-1.5-flash\", model_config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/generative_models.py\", line 85, in __init__\n",
      "    self._safety_settings = safety_types.to_easy_safety_dict(safety_settings)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/types/safety_types.py\", line 224, in to_easy_safety_dict\n",
      "    return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/types/safety_types.py\", line 224, in <dictcomp>\n",
      "    return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/types/safety_types.py\", line 107, in to_harm_category\n",
      "    return _HARM_CATEGORIES[x]\n",
      "           ~~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 'temperature'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/31/pnynpc9d6g141fp9hhncsc700000gn/T/ipykernel_63383/2264098060.py\", line 56, in lyrics_expert\n",
      "    except StopCandidateException as safety_error:\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'StopCandidateException' is not defined\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/31/pnynpc9d6g141fp9hhncsc700000gn/T/ipykernel_63383/2264098060.py\", line 23, in lyrics_expert\n",
      "    model = genai.GenerativeModel(\"gemini-1.5-flash\", model_config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/generative_models.py\", line 85, in __init__\n",
      "    self._safety_settings = safety_types.to_easy_safety_dict(safety_settings)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/types/safety_types.py\", line 224, in to_easy_safety_dict\n",
      "    return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/types/safety_types.py\", line 224, in <dictcomp>\n",
      "    return {to_harm_category(key): to_block_threshold(value) for key, value in settings.items()}\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/google/generativeai/types/safety_types.py\", line 107, in to_harm_category\n",
      "    return _HARM_CATEGORIES[x]\n",
      "           ~~~~~~~~~~~~~~~~^^^\n",
      "KeyError: 'temperature'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/chengu/Desktop/anaconda3/lib/python3.11/site-packages/gradio/utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/31/pnynpc9d6g141fp9hhncsc700000gn/T/ipykernel_63383/2264098060.py\", line 56, in lyrics_expert\n",
      "    except StopCandidateException as safety_error:\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'StopCandidateException' is not defined\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import gradio.themes  # Import Gradio themes\n",
    "\n",
    "# Define a theme for the app\n",
    "theme = gr.themes.Soft(primary_hue=\"blue\", font=\"Comic Sans MS\")\n",
    "\n",
    "# Example inputs for users to try\n",
    "examples = [\n",
    "    [\"Can you suggest a song with the keyword 'love'?\", None],  # Text-only example\n",
    "    [\"I'm feeling down, can you suggest some positive songs?\", None],  # Text with mood\n",
    "]\n",
    "\n",
    "# Define the Gradio interface\n",
    "with gr.Blocks(theme=theme) as app:\n",
    "    lyrics_chatbot = gr.Chatbot(label=\"🎶 Your Personal Lyrics Expert 🎶\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=7):\n",
    "            user_input = gr.Textbox(label=\"Ask a Question\", placeholder=\"Ask about song lyrics, moods, or keywords.\")\n",
    "        with gr.Column(scale=3):\n",
    "            image_input = gr.Image(label=\"Upload Album Cover (Optional)\", type=\"pil\")\n",
    "\n",
    "    # Add sliders for temperature, top-k, and top-p (Model Parameters)\n",
    "    temperature_slider = gr.Slider(minimum=0.0, maximum=1.0, value=0.7, label=\"Temperature\")\n",
    "    top_k_slider = gr.Slider(minimum=0, maximum=100, value=50, label=\"Top-K\")\n",
    "    top_p_slider = gr.Slider(minimum=0.0, maximum=1.0, value=0.9, label=\"Top-P\")\n",
    "\n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    rewind_btn = gr.Button(\"Rewind Chat\")\n",
    "\n",
    "    # Keep the chat history\n",
    "    conversation_history = gr.State([])\n",
    "\n",
    "    # Define example inputs (text or image) for users to try\n",
    "    gr.Examples(\n",
    "        examples=examples,  \n",
    "        inputs=[user_input, image_input],  \n",
    "        label=\"Try some example questions and requests\"\n",
    "    )\n",
    "\n",
    "    # Submit button to handle the lyrics expert function\n",
    "    submit_btn.click(\n",
    "        fn=lyrics_expert,  # The function handling lyrics queries\n",
    "        inputs=[user_input, image_input, conversation_history, temperature_slider, top_k_slider, top_p_slider], \n",
    "        outputs=[lyrics_chatbot, conversation_history]\n",
    "    )\n",
    "\n",
    "    # Rewind button to clear chat history (or go back a step)\n",
    "    rewind_btn.click(\n",
    "        fn=lambda conversation_history: ([], \"Chat history cleared!\"),  # Clear history\n",
    "        inputs=conversation_history, \n",
    "        outputs=[lyrics_chatbot, conversation_history]\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
